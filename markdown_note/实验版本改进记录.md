#### V0211

- 超参数的调参（**SGD函数换Adam函数，学习率仍为1e-3**）
- 对图像的预处理代码（加入了标准化使用Imagenet的参数mean和std，使用cv2转RGB）

- 评价标准MIoU（v0210：可运行，但是由于强转int导致结果一直都是1.0，应该错误）
- **使用更深层的网络进行训练(resnet-152)**
- 结果证明：**SGD及深层网络都有益于实验结果**
- **关于标准化的想法：本来是想直接使用PIL的Image去直接读取RGB图像，然后进行标准化，结果出现的错误无法解决，改用cv2，cv2读取的是BGR图像，又采用cv2转RGB，接着进行标准化，结果很差。**

- <u>**思考待解决：1. 标准化参数应该由真实图像求得； 2. 不使用转RGB，改换参数位置**</u>

#### V0217

- **改进了MIoU的计算代码，以及可求得Acc及Class_acc（基于混淆矩阵）**
- **修复了之前的预测问题，4个一组进行预测结果很差，改为1个1个预测，结果正确**

#### V0219

- **证实了Adam更优**
- **此时的数据是640大小的尺寸，测试集的分配类别不平衡，其中车辆建筑信息过于少，地面道路过于多**

- **参与模型进行大图预测，结果提示CUDA内存不足，于是切割大图为两张，切割完进行预测，其中训练集部分的结果很好，但是测试集的预测结果很差**

#### V0225

- **重新分配训练集、测试集，数据切割为320大小，数据增强后，数据量提高**
- **在预测时，模型对图的尺寸很敏感，无法对输入的大图进行预测，但是在320大小的测试集上表现好**
- 当时想要改进的地方：
  - **数据划分比例，训与验，其次还考虑到以下问题：普通的交叉验证有可能选的val验证集不好，考虑k折交叉验证方法，每次更换验证集和训练集 **
  - batch_size改为多少合适
  - **模型复杂度（换模型、保存参数）**
  -  训练时的提前停止策略

#### V0301

- **替换网络为基于resnet50，测试较简单模型的效果**
- 在val中记录acc等指标，tensorboard
- **保存模型参数，减小内存使用（预测时还是cuda内存不足）** <u>结果还是不能载入预测完整大图</u>
- 在320大小的测试集上计算指标数据，结果发现v0225优于v0301

#### V0304

- **替换验证集的方式为****k折交叉验证
- 已完成数据集的载入；**测试输出图像的名称train和val无交集**
- 完成**train部分的代码，在一个epoch中交叉验证**
- 结果：**epoch40得出的结果与v0225版本epoch200结果相差不多**

#### V0316

- **测试了两种deeplabv3+网络，都不如deeplabv3**
- **实验中发现采用resnet的预训练模型可能有效，于是进行V0304版本的预训练参数训练**

#### 目前的实验结果：V0304最优

- **v3p_v0304、v0304、v0301、v0225版本结果比较**
- V0225：deeplabv3-resnet152 + 普通留出验证
- v0301：deeplabv3-resnet50 + 普通留出验证
- v0304：deeplabv3-resnet152 + 5折交叉验证
- V3p-101：deeplabv3+_resnet101预训练模型 + 5折交叉验证
- V3p-152：deeplabv3+_resnet152 + 5折交叉验证

|         |  Acc   |  MIoU  | Kappa  |  地面  |  房屋  |  道路  |  车辆  |
| :-----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |
|  V0225  | 0.9562 | 0.7864 | 0.8477 | 0.9847 | 0.8531 | 0.8898 | 0.7269 |
|  V0301  | 0.9545 | 0.7740 | 0.8429 | 0.9815 | 0.8849 | 0.9037 | 0.6313 |
|  V0304  | 0.9555 | 0.7777 | 0.8470 | 0.9816 | 0.8529 | 0.9086 | 0.7151 |
| V3p-101 | 0.9544 | 0.7706 | 0.8427 | 0.9785 | 0.8704 | 0.9165 | 0.5758 |
| V3p-152 | 0.9525 | 0.7582 | 0.8317 | 0.9860 | 0.8235 | 0.9111 | 0.6009 |
